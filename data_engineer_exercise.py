# -*- coding: utf-8 -*-
"""data_engineer_exercise.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uelkx1kmpbSWPDn5L1BVYupc8H2t_2AH

# Data Engineer Exercise

## Description

In the following code, I will use the three files "cons.csv", "cons_email.csv", and "cons_email_chapter_subscriptions.csv" to create two new files: "people" and "acquisition_facts" based on the required metrics.

## Packages and Data Importing
"""

# Packages: pandas
import pandas as pd

# Import .csv files from working directory 

cons = pd.read_csv("cons.csv")
cons_email = pd.read_csv("cons_email.csv")
cons_email_chapter_subscription = pd.read_csv(
    "cons_email_chapter_subscription.csv")

# Check formatting of data 

print(cons.columns)
print(cons_email.columns)
print(cons_email_chapter_subscription.columns)

"""## Task 1: "people" file"""

# We want "email" from the cons_email.csv file
# We want "create_dt" and "modified_dt" from the cons.csv file 
# (Because we want to know when the *person's* file was created, not their email)
# We also want "subsource" to create the "code" column
# Finally, we want "isunsub" from the cons_email_chapter_subscription.csv file

# Merge data frames - outer join first to not lose any data 
cons_join = cons.merge(cons_email, on = ["cons_id"], how = "outer")
cons_join = cons_join.merge(cons_email_chapter_subscription, 
                            on = ["cons_email_id"], how = "outer")

# Keep only primary emails 

cons_join = cons_join[cons_join["is_primary"] == 1.0]

# Keep only rows where chapter_id is 1

cons_join = cons_join[cons_join["chapter_id"] == 1.0]

# As indicated in the instructions, if an email has a chapter_id = 1, but does
# not have isunsub listing, then isunsub should get 0. 
# It looks like this condition does not occur. 

cons_join["isunsub"].isnull().values.any()

# Create people dataframe 
# The create_t and modified_dt we want are the "x" ones

people = cons_join[["email", "source", "subsource", "isunsub", "create_dt_x", 
                    "modified_dt_x"]].reset_index(drop = True)

# Rename columns to requested

people.columns = ["email", "source", "subsource", "is_unsub", "created_dt", 
                  "updated_dt"]

# Check if new df was created properly

people.head(10)

# Check on datatypes of new df 

people.dtypes

# Fix NaN's so they can be used as strings

people["source"] = people["source"].fillna("NA")
people["subsource"] = people["subsource"].fillna("NA")

# Change datatypes to requested 

people["email"] = people["email"].astype("string")
people["source"] = people["source"].astype("string")
people["subsource"] = people["subsource"].astype("string")
people["is_unsub"] = people["is_unsub"].astype("bool")
people["created_dt"] = pd.to_datetime(people["created_dt"])
people["updated_dt"] = pd.to_datetime(people["updated_dt"])

# Create a code column that contains source and subsource

people["code"] = people["source"] + ": " + people["subsource"]
people = people[["email", "code", "is_unsub", "created_dt", "updated_dt"]]
people["code"][people["code"] == "NA: NA"] = "NA"

# Check datatypes again

people.dtypes

# Save df to working directory 

people.to_csv("people.csv")

"""## Task 2: "acquisition_facts" file """

# Get dates from datetime column

acquisition_dates = people["created_dt"].dt.date

# Create df

acquisition_facts = pd.value_counts(acquisition_dates).to_frame().reset_index()

# Rename columns

acquisition_facts.columns = ["acquisition_date", "acquisitions"]

# Sort by date 

acquisition_facts = acquisition_facts.sort_values(
    by = "acquisition_date", ascending = False).reset_index(drop = True)

# Check to see if dataframe was created properly 

acquisition_facts.head(10)

# Check datatypes

acquisition_facts.dtypes

# Change datatypes to match requested
# Change date column to date  

acquisition_facts["acquisition_date"] = pd.to_datetime(
    acquisition_facts["acquisition_date"]).dt.normalize()

# Check datatypes again

acquisition_facts.dtypes

# Save to working directory 

acquisition_facts.to_csv("acquisition_facts.csv")